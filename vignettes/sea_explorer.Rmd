---
title: "Handling SeaExplorer Data"
author: "Dan Kelley (https://orcid.org/0000-0001-7808-5911)"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
    fig_caption: yes
    fig_width: 6
    fig_height: 4
    dpi: 72
vignette: >
  %\VignetteIndexEntry{Handling SeaExplorer Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

**Abstract.** This vignette explains the basics of working with data from
SeaExplorer gliders.  It is VERY MUCH a work in progress, not much more than a
skeleton.

# Raw Files


## Downloading the files

The below shows how to download a small number of files (just 5) from the
CPROOF server at Reference 1. The code worked as of 2024-08-29, but if reader
finds that the server has changed, the solution is to alter the value of
`urlbase` in line 2 below.

```{r}
n <- 5 # number of files to download
urlRaw <- paste0(
    "https://cproof.uvic.ca/gliderdata/deployments/",
    "dfo-eva035/dfo-eva035-20231019/",
    "delayed_raw/"
)
subs <- paste0("sea035.118.gli.sub.", 1:n)
raws <- paste0("sea035.118.pld1.raw.", 1:n)
for (i in 1:n) {
    if (!file.exists(subs[i])) {
        download.file(paste0(urlRaw, subs[i]), subs[i])
    }
    if (!file.exists(raws[i])) {
        download.file(paste0(urlRaw, raws[i]), raws[i])
    }
}
```

Note that the above is based on the assumption that the server holds the `sub`
and `pld1` files in the same directory.  If your server holds them in separate
directories, it should be a simple matter to alter the lines defining `subs`
and `raws` in the above.

## Trimming spurious data after power-on

Raw SeaExplorer data files may contain spurious values after the sensors are
powered on.   This may occur at the start of a deployment, but it may also
occur later on in the data set, if the glider was set up to power-down the
sensors from time to time.

To avoid problems with analysis, it makes sense to trim data acquired just
after power-on events. The `read.glider.seaexplorer.delayed()` function has a
parameter called `removeTimeSincePowerOn` that does just this. It's value is
the number of seconds of of data that are to be ignored after power-on events.

There may be statistical ways to determine these spurious data (e.g. looking
for salinities below a certain fixed threshold, or a certain quantile), but a
quicker method is to do this by examining plots of data. This is illustrated in
the following code.

In the plot call, note that the `type` is set to give points. This is required,
because the default setting of `type="l"` will skip over quite a lot of the
data because there are so many NA values between valid points.  Indeed, for
this dataset, 3/4 of the data are NA.

```{r fig.height=4, fig.width=7, fig.cap="**Figure 1. Raw data, without trimming after power-on. Note the spuriously low salinities and odd temperatures before about 20:15 or so.**", dev.args=list(pointsize=12)}
library(oce)
library(oceglider)
g <- read.glider.seaexplorer.delayed(".")
layout(rbind(c(1, 2), c(3, 2)), widths = c(0.6, 0.4))
oce.plot.ts(g[["time"]], g[["temperature"]],
    ylab = "Temperature", type = "p", cex = 0.3
)
ctd <- as.ctd(g[["salinity"]], g[["temperature"]], g[["pressure"]])
plotTS(ctd, eos = "unesco")
oce.plot.ts(g[["time"]], g[["salinity"]],
    ylab = "Salinity", type = "p", cex = 0.3
)
```

Obviously, the salinities are highly spurious at the start.  And, after that,
there is a ramp-up period that is also suspicious.  Temperature is also odd,
having a different character of variation before and after the time of spurious
salinity.  The temperature-salinity diagram is also a good indication that the
initial data are not representative of the ocean.

Visual inspection puts the spurious time at somewhere between 1 and 2 hours
since the first plotted point.  The use of `locator()` can narrow this down
more precisely, but for illustration, we'll try 1.5 hours.

```{r fig.height=4, fig.width=7, fig.cap="**Figure 2. Raw data, after trimming spurious data in the 1.5 hours following power-on events.**", dev.args=list(pointsize=12)}
library(oce)
library(oceglider)
skip <- 1.5 * 3600 # 1.5 hours, in seconds
g <- read.glider.seaexplorer.delayed(".", removeTimeSincePowerOn = skip)
layout(rbind(c(1, 2), c(3, 2)), widths = c(0.6, 0.4))
oce.plot.ts(g[["time"]], g[["temperature"]],
    ylab = "Temperature", type = "o", cex = 0.3
)
ctd <- as.ctd(g[["salinity"]], g[["temperature"]], g[["pressure"]])
plotTS(ctd, eos = "unesco")
oce.plot.ts(g[["time"]], g[["salinity"]],
    ylab = "Salinity", type = "o", cex = 0.3
)
```

With this skipping of initial data following the power-up, we have data that
are of the expected character. The time series plots show an expected pattern
for a glider that is moving up and down in the water column.  The
temperature-salinity diagram also looks sensible.

As noted, statistical methods might also be useful in determining
whether this sort of data trimming is warranted.  For example,
for this particular dataset, the spuriously fresh water could
be detected using the `quantile()` function, with a 2 percent
level as the criterion.  However, that number would need to be
changed if the whole dataset were to be used.  Given the ease
with which this kind of work can be done visually, as above,
there seems to be little need to suggest more quantitative
methods.  Besides, there is great merit in looking at the data,
at the earliest opportunity.

# Delayed-mode NetCDF Files

The first step is to download the data.  This can take a minute or two,
depending on the connection speed, so the code below skips the downloading
step, if the file already exists locally.


```{r}
urlNC <- paste0(
    "https://cproof.uvic.ca/gliderdata/deployments/",
    "dfo-eva035/dfo-eva035-20231019/",
    "/L0-timeseries/dfo-eva035-20231019_delayed.nc"
)
fileNC <- gsub(".*/", "", urlNC)
# 86.8MB file, so cache it to save O(30) second download.
if (!file.exists(fileNC)) {
    download.file(urlNC, fileNC)
}
```

Next, read the data. This takes only a second or two.
```{r}
library(oce)
library(oceglider)
G <- read.glider.netcdf(fileNC)
summary(G)
#<debugging units> print(G@metadata$units)
#<debugging units> library(ncdf4)
#<debugging units> nc <- nc_open("dfo-eva035-20231019_delayed.nc")
#<debugging units> units <- list()
#<debugging units> names(nc$var)
#<debugging units> ncatt_get(nc, "temperature")$units
#<debugging units> as.unit(tolower(ncatt_get(nc, "temperature", "units")$value))
#<debugging units> units[["temperature"]] <- as.unit(ncatt_get(nc, "temperature", "units")$value)
#<debugging units> units[["depth"]] <- as.unit(ncatt_get(nc, "depth", "units")$value)
#<debugging units> names(nc$var)
#<debugging units> for (v in names(nc$var)) {
#<debugging units>     unit <- ncatt_get(nc, v, "units")$value
#<debugging units>     cat(v, " :  ", unit, "\n")
#<debugging units>     cat(" -- ", as.character(as.unit(unit, "copy")$unit), "\n")
#<debugging units> }
#<debugging units> print(units)
```

A summary is usually helpful, so we start with that.  Note that the original
names (as stored in the NetCDF file) use snake-case notation (with underlines
joining words) but that these are converted to camel-case notation (with
upper-case letters at the start of second and later words). The `[[` notation
works with either, but we stick here to the oce names, so the code will be
familiar to users of that package.

```{r}
summary(G)
```

Another good way to get an overview is with some plots.  First, let's
see where the data were acquired.  It helps to set the `type` parameter
to yield line segments between the data, rather than points, so
we can more easily see retracing.

```{r}
plot(G, which = "map", type = "l")
```

This indicates sampling on the west coast of Canada. The
first samples were likely on the east, and the glider travelled
to the southwest, before turning around and retracing its
route to about 131W.  Presumably it was picked up
by a ship then.

Let's learn more about the water column by plotting pressure
versus time.

```{r}
plot(G, which = "p")
```

This verifies the assumption that the early data were on the shelf.  Note that
the device must have been set to return to the surface when it got to a depth
of 1 kilometre at about 2023-10-27.

Let's look at temperature on the continental shelf, by selecting just the first
week of data.

```{r}
Gs <- subset(G, time < G[["time"]][1] + 7 * 86400)
temperature <- Gs[["temperature"]]
cm <- oce::colormap(temperature, col = oceColorsTurbo)
par(mar = c(3, 3, 1, 1))
drawPalette(colormap = cm)
plot(Gs, which = "p", type = "p", col = cm$zcol, mar = c(3, 3, 1, 4))
```

The overall pattern look sensible for this domain, but notice that there are
very few parts of the image that are read. Closer inspection shows that that
end of the temperature scale may be controlled by the very first data points.

What of salinity?  It shows a similar pattern.

```{r}
salinity <- Gs[["salinity"]]
cm <- oce::colormap(salinity, col = oceColorsTurbo)
par(mar = c(3, 3, 1, 1))
drawPalette(colormap = cm)
plot(Gs, which = "p", type = "p", col = cm$zcol, mar = c(3, 3, 1, 4))
```

The sensible next step is to draw a temperature-salinity diagram, to get an
idea of the outliers.

```{r}
plot(Gs, which = "TS")
```

Taking these last three plots together, it is obvious that
there are some serious outliers.  A time-series plot can help.

```{r}
layout(matrix(c(1, 3, 2, 3), byrow = TRUE, nrow = 2), widths = c(0.6, 0.4))
plot(Gs, which = "T", type = "p", cex = 0.3)
plot(Gs, which = "S", type = "p", cex = 0.3)
plot(Gs, which = "TS")
```

We need a way to skip over those initial data. A bit
of exploration suggests that skipping the first 2 hours
will remove those data.

```{r}
Gss <- subset(Gs, time > time[1] + 2 * 3600)
layout(matrix(c(1, 3, 2, 3), byrow = TRUE, nrow = 2), widths = c(0.6, 0.4))
plot(Gss, which = "T", type = "p", cex = 0.3)
plot(Gss, which = "S", type = "p", cex = 0.3)
plot(Gss, which = "TS")
```

What to do next?  That depends, of course, on the wishes of the analyst.  At
this point, it should be clear how to read in data using
`read.glider.netcdf()`, how to extract data with `[[,glider-method`, how to
isolate subsets of data with `subset,glider-method()`, and how to use
`plot,glider-method()` to make some useful plots.


# FIXME

1. Move quite a few SeaExplorer-specific things from the
   general vignette here. Example: navstate

2. ~Talk about the big nc files~

3. When cleaned up, use tmp dir.

# References

1. “Index of
   /Gliderdata/Deployments/Dfo-Eva035/Dfo-Eva035-20231019/Delayed_raw.”
   Accessed August 28, 2024.
   <https://cproof.uvic.ca/gliderdata/deployments/dfo-eva035/dfo-eva035-20231019/delayed_raw/>


